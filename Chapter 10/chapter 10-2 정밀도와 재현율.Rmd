---
title: "chapter 10-1 exercise"
author: "kangminji"
date: '2021 5 4 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rpart)
library(caret)
#install.packages("randomForest")
library(randomForest)
library(caret)
library(e1071)
```

```{r}
ucla <-  read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
ucla$admit <- factor(ucla$admit)

```

UCLA데이터에 대해서 Cross validation을 하고 4가지 모델에 대해서 정확도, 정밀도, 재현율을 구하시오

```{r}
set.seed(2021)
data <- ucla[sample(nrow(ucla)),]
options(digits = 4)
```


```{r}
k <- 5
q <- nrow(data)/k      #nrow: 행의 수
l <- 1:nrow(data)
```

decision tree
```{r}
accuracy <- 0
precision <- 0
recall <- 0

for (i in 1:k) {
  test_list <- ((i-1)*q+1):(i*q)    #1:30, 31:60, 61:90 ...
  testData <- data[test_list,]
  trainData <- data[-test_list,]
  
  dt <- rpart(admit~.,trainData)
  pred <- predict(dt, testData, type = 'class')
  t <- table(pred, testData$admit)

  accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(testData)
  precision <- precision+t[2,2]/(t[2,1]+t[2,2])
  recall <- recall + t[2,2]/(t[2,1]+t[2,2])
}

dt_avg_acc <- accuracy / k
dt_avg_prec <- precision / k
dt_avg_rec <- recall / k

options(digits = 4)

```
랜덤포레스트
```{r}
accuracy <- 0
precision <- 0
recall <- 0

for (i in 1:k) {
  test_list <- ((i-1)*q+1):(i*q)    #1:30, 31:60, 61:90 ...
  testData <- data[test_list,]
  trainData <- data[-test_list,]
  rf <- randomForest(admit~.,trainData)
  pred <- predict(rf, testData, type = 'class')
  t <- table(pred, testData$admit)

  accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(testData)
  precision <- precision+t[2,2]/(t[2,1]+t[2,2])
  recall <- recall + t[2,2]/(t[2,1]+t[2,2])
}

rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k

```
SVM
```{r}
accuracy <- 0
precision <- 0
recall <- 0

for (i in 1:k) {
  test_list <- ((i-1)*q+1):(i*q)    #1:30, 31:60, 61:90 ...
  testData <- data[test_list,]
  trainData <- data[-test_list,]
  svm <- svm(admit~.,trainData)
  pred <- predict(svm, testData, type = 'class')
  t <- table(pred, testData$admit)

  accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(testData)
  precision <- precision+t[2,2]/(t[2,1]+t[2,2])
  recall <- recall + t[2,2]/(t[2,1]+t[2,2])
}

sv_avg_acc <- accuracy / k
sv_avg_prec <- precision / k
sv_avg_rec <- recall / k
```
knn
```{r}
accuracy <- 0
precision <- 0
recall <- 0

for (i in 1:k) {
  test_list <- ((i-1)*q+1):(i*q)    #1:30, 31:60, 61:90 ...
  testData <- data[test_list,]
  trainData <- data[-test_list,]
  pred <- knn(trainData)
  pred <- predict(knn, testData, type = 'class')
  t <- table(pred, testData$admit)

  accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(testData)
  precision <- precision+t[2,2]/(t[2,1]+t[2,2])
  recall <- recall + t[2,2]/(t[2,1]+t[2,2])
}

kn_avg_acc <- accuracy / k
kn_avg_prec <- precision / k
kn_avg_rec <- recall / k

```

```{r}
sprintf('결정트리: 정확도=%f, 정밀도=%f, 재현율=%f',
        dt_avg_acc, dt_avg_prec, dt_avg_rec)
sprintf('랜덤 포레스트: 정확도=%f, 정밀도=%f, 재현율=%f',
        rf_avg_acc, rf_avg_prec, rf_avg_rec)
sprintf('SVM: 정확도=%f, 정밀도=%f, 재현율=%f',
        sv_avg_acc, sv_avg_prec, sv_avg_rec)
sprintf('K-NN: 정확도=%f, 정밀도=%f, 재현율=%f',
        kn_avg_acc, kn_avg_prec, kn_avg_rec)
```




